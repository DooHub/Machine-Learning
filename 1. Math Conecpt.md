# 1. Vector란, 왜 필요한 가?
 ### 1) Vector는 크기와 방향을 나타내는 표현식으로, 정보 또는 물리적 특성을 표현 할 수 있다. 예) 사람들의 키와 몸무게 비교, 힘의 크기와 방향
 ### 2) Vector에서 +/-는 방향을 나타내며, 같은 크기의 두 개의 같이 다른 부호를 가진다는 것은 방향을 서로 반대 임을 의미 한다.
 ### 3) 방향은 없고, 크기만 있는 것을 Scalar라고 한다. Scalar의 부호는 Vector와 결합 될 경우 방향성의 의미를 가진다.
 ### 4) Vetor는 두 개의 형태가 있다 Vector의 구성요소(Element)가 세로 표현 된 경우 종벡터(열벡터)라고 하고 가로로 표현할 경우는 횡벡터(행벡터)라고 한다.
``` python
#Python에서는 List가 Column Vector에 해당한다.
# Row Vector을 구현하기 위해서는 numpy을 이용한 array로 변경이 필요 하다.

import numpy as np

list1 = [1, 2, 3]  # Your 1-D list
list2 = [[10], [20], [30]]  # A 2-D list (vertical vector)

vector1 = np.array(list1)  # Create a horizontal vector
vector2 = np.array(list2)  # Create a vertical vector

```

# 2. Matrix(행렬)이란 무엇 인가?
 ### 1) Matrix은 행과 열이 있는 2차원 구조를 말한다. Matrix에서도 Matrix 내 각 값을 Element(요소)라고 한다.  
 ###    ***(Vector에서 차원은 element의 갯수를 말하기 때문에 구분 해야 한다.)***
 ```python
# matrix라는 Method가 있지만, array를 사용하면 메모리와 산술 방식이 더 다양한다. - Matrix 간 단순 곱셈이 가능 (Matrix prouct가 아님)

import numpy as np
x=np.array([1,0,0],[0,1,0],[0,0,1])

```
### 2) 행렬의 종류
#### a. Zero matrix - Element값이 모두 0 인 겨우
#### b. Square Matrix(정방행렬) - 행과 열의 크기가 같은 경우
#### c. diagonal matrix(대각행렬) - 정방행렬이면서, 대각선에 해당하는 element만 0이 아니고 나머지는 0인 행렬
#### d. identity martix(항등행렬) - 대각행렬 중에서 대각선 값이 모두 1인 행렬
#### e. Upper triangular matrix(상삼각행렬) - 대각선 기준 위쪽에만 값이 있는 경우
#### f. lower triangular matrix(하삼각행렬) - 대각선 기준 아래쪽에만 값이 있는 경우
#### g. transpose matrix(전치행렬) - 기존 행렬에서 대각선 중심으로 행과 열을 바꾸어 얻는 행 A의 전치행렬 $A^{T}$ 이며 $(A^{T})^{-1}=(A^{-1})^{T}$
#### h. inverse matrix(역행렬) - 행렬 A가 존재 할 때, 다음이 성립하는 행력 B를 A의 역행렬이라고 한다. $AB=I=AA^{-1}, \quad (\therefore B=A^{-1})$


```python
import numpy as np

# Create a 3x3 zero matrix
zero_matrix = np.zeros((3, 3))

# Create a 4x4 square matrix
square_matrix = np.array([[1, 2, 3, 4],
                          [5, 6, 7, 8],
                          [9, 10, 11, 12],
                          [13, 14, 15, 16]])

# Create a 3x3 diagonal matrix
diagonal_matrix = np.diag([2, 4, 6])

# Create a 3x3 identity matrix
identity_matrix = np.eye(3)

# Create a 3x3 upper triangular matrix
upper_triangular_matrix = np.triu([[1, 2, 3],
                                   [0, 4, 5],
                                   [0, 0, 6]])
# Create a 3x3 lower triangular matrix
lower_triangular_matrix = np.tril([[7, 0, 0],
                                   [8, 9, 0],
                                   [10, 11, 12]])
# Create a sample matrix
A = np.array([[1, 2, 3],
              [4, 5, 6]])

# Compute the transpose
A_transpose = np.transpose(A)

```
# 3. Vector 연산
### 1) Inner product(내적) - 수식에 보는 것 같이 물리적의미는 두 벡터가 얼마나 같은 방향을 향하고 있는지 나타낸다 $\theta$가 0도이면 값은 1이 되면 있는 같은 방향을 나타 낸다.  
###  $\quad \quad A\cdot B=\left| A \right|\left| B \right| \text cos \theta$
###                          다시 말해 힘이 변위 방향으로 얼마나 일을 했는지를 나타낸다. 따라서 내적의 값은 크기만을 나타 내기 때문에 Scalar가 된다
### 2) outer product(외적) - 수식에서 보는 것이 같이 외적는 또 다른 벡터를 생성한다. 수식적 의미는 두 벡터가 만드는 단위 면적을 면적을 계산하고 이를 면적에 수직인 단위 벡터(n)에 투영한 것이다.  
### $\quad \quad A\times B=\left| A \right|\left| B \right| \text sin \theta \text n \quad (\text n = unit \ vecotr )$
### 물리적 의미로는 회전하는 물체의 운동량을 나타낸다. 예를 들어 nut을 회전 시 회전 방향에 수직으로 nut가 이동하는 것을 알 수 있다.
# 4. 행렬 연산의 의미와 활용
### 1)행렬의 연산 법칙
### $\quad \quad AB\neq BA, \quad \quad A(BC)=(AB)C, \quad \quad A(B+C)=AB+BC,(A+B)C=AC+BC$
### 2) 행렬의 연산의 의미는 행렬의 값이 변경 되는 것을 의미 하는데, 이는 공간이나 상태가 변형 된 것을 의미 한다. 이를 사영(Projection)이라고 한다.  
### 다시 말해서 어떤 행렬(Data)에 다른 행렬을 연산하면 또 다른 행렬이 생성 되기 때문에 다른 행렬을 함수 혹은 필터로 간주 할 수 있다.
### 3) I을 항등 행렬이라고 할 때, $AA^{-1}=I=A^{-1}A$가 성립하면 A를 nonsingluar matrix, invertible matrix 혹은 regular matrix라고 한다. 이 때 $A^{-1}$는 A의 역행렬이 된다.
### 4) det(A)를 행렬 A의 행렬식(determinant)라고 하며, 그 값은 Scalar 값이 된다. ***det(A)를 구하기 위해서는 A는 정방행렬(Sqaure Matrix)이어야 한다.***

$$A=\begin{bmatrix}
a &b  \\
c &d 
\end{bmatrix}, \quad
A^{-1}=\frac{1}{det(A)}\begin{bmatrix}
d &-b  \\
-c &a 
\end{bmatrix}, \quad
det(A)=\left| A \right|=ad-bc$$


```python

import numpy as np

# Create a sample matrix (2x2)
# Matrix should be a squre matrix

matrix = np.array([[3, 1],
                   [2, 4]])

# Compute the determinant
determinant = np.linalg.det(matrix)
```
### ***역행렬을 구하기 위해서는 하기 위해서는 상기 공식에서 우선 det(A)가 0이 아니어야 한다. (1을 0으로 나눌 수 없음)***

### 5) Marko Chain이란 연쇄적으로 어떤 상태를 확률 모형화 한 것을 말한다. 예를 날씨(비 오거나 맑음)에 대해 하기와 같이 Matrix구조로 만들 수 있으며  
### 이 때 만들어진 Matrix을 전이 행렬(Transition matrix)라고 한다. 이 전이행렬들의 곱을 통해 몇일 후의 날씨에 상태에 대해 확률적 접근이 가능하다.


|       |      | Tomorrow | Tomorrow |
|-------|------|----------|----------|
|       |      | Rain     | Fine     |
| Today | Rain | 0.6      | 0.4      |
| Today | Fine | 0.5      | 0.5      |

# 4. 행렬의 분해
### 1) 행렬 단순화  
### 전이행렬의 곱을 계산 할 때 전이 행렬의 모든 element가 값을 가지면 계산하기가 어렵다.하지만 대각행렬(diagonal Matrix)로 변경 할 수 있다면 계산은 빠르게 진행 될 수 있다.

$$M=\begin{bmatrix}
 0.1& \cdots  & 0.4 \\
\cdots  & 0.6 &  \cdots \\
0.4 &\cdots   & 0.5
\end{bmatrix} \quad M^{5}=MMMMM \quad \quad P^{-1}MP=D \quad(D:diagonal \ matrix)$$

### $PP^{-1}MPP^{-1}=PDP^{-1} \to IMI=PDP^{-1} \quad (\therefore M=PDP^{-1})$
### $M^{5}=MMMMM=PDP^{-1}PDP^{-1}PDP^{-1}PDP^{-1}PDP^{-1} =PDIDIDIDIDP^{-1}=PDDDDDP^{-1}$
### 같은 값의 대가행렬의 거듭제곱은 각 element의 거듭제곱으로 표현 가능하다. 이런 표현을 분해(decomposition)이라고 한다.
$$ M=\begin{bmatrix}
1 & 0 & 0  \\
0 & 2 & 0 \\
0 &0  & 3
\end{bmatrix}, \quad MM=
\begin{bmatrix}
1 & 0 & 0  \\
0 & 2 & 0 \\
0 &0  & 3
\end{bmatrix} \times
 \begin{bmatrix}
1 & 0 & 0  \\
0 & 2 & 0 \\
0 &0  & 3
\end{bmatrix} =
 \begin{bmatrix}
1^2 & 0 & 0  \\
0 & 2^2 & 0 \\
0 &0  & 3^2
\end{bmatrix}$$

### 2) 고윳값(eigenvalue, characteristic value)과 고유벡터(eigenvector,characteristic vector)  
### A가 정방 행렬(nXn)이고 x는 원소 n개를 가지는 벡터, $\lambda$는 상수이며, 하기 식이 성립 할 경우, x와 $\lambda$를 고유벡터와 고윳값으로 정의 한다.  
### x가 0이 아닌 해를 가지기 위해서는 $(A-\lambda I)$가 역행렬을 가지면 안 된다. 
### $Ax=\lambda x \longrightarrow (A-\lambda I)x=0 \quad\quad\quad \text{if} \ x\neq 0,\ det(A-\lambda I)=0$
### 식 $det(A-\lambda I)=0$을 A의 특성방정식(Characteristic equation)이라고 하며, 이 방식을 통해 $\lambda$를 구하고 이를 바탕으로 x를 구할 수 있다.
### 고유벡터의 개수는 이론적으로 최대 행렬의 차수 n과 같지만, 실제로는 기하적 중복도와 대수적 중복도에 따라 달라질 수 있다.
### 결론적으로 어떤 행렬(사람들의 몸무게와 키)의 고윳값과 고유 벡터를 구하면 그 행렬의 특징을 알 수 있다. 이 값들을 필터와 같은 역할을 하며 다른 행렬과의 관계를 파악 할 수 있게 도와 준다.  
### 다시 말해, 고윳값은 크기를 나타내는 역할(내적을 거치면, 길이가 바뀜), 고윳벡터는 방향을 나타 낸다.

# 5. 주성분 분석
### 어떤 행렬을 고윳값과 고유벡터로 표현 할 수 있다는 것은, 고윳값과 고유베터로 어떤 행렬을 대신 할 수 있다는 의미이다.  
### 복잡한 행렬은 보다 단순한 고윳값과 고유벡터로 표현 할 수 있다면 이는 Raw data의 크기가 작아 진 것으로, 이를 차원 축소(diemnsion reduction)라 한다.  
### 이런 기법을 주성분 분석(PCA : Principal Component Analysis) 이라고 한다. 여기서 말하는 차원의 축소는 변수의 개수를 의미 하는 것이 행렬의 행과열의 차수를 의미 하지는 않는다.  
### 주성분 분석이랑 기본적으로 고윳값과 고유 벡터를 활용하여 자료(Matrix)를 다르게 표현하는 것이다. 따라서 주성분은 기존 변수의 선형 변환을 통해 상관관계가 적은 새로 만들어진 변수를 의미 한다.  
### 이를 수식으로 표현하면 일차식으로 표현 할 수 있다.    주성분 =계수 X 원데이터(Raw Data) + 절편
### 주성분은 최대로 원래 변수의 개수 만큼 만들 수 있다. 다만 첫번째 주성분이 원데이터를 최대한 잘 표현하다 보니 마지막 번째의 주성분은 별로 영양가 없어 의미가 별로 없다. (따라서 주성분은 변수 개수보다 작다.)     
### 주성분의 개수를 선택하기 위해서는 선택 된 주성분 간에 연관 관계가 없어야 최소한의 주성분들로 원데이터를 잘 표현 할 수 있다.   
### 주성분은 일차식으로 표현 되기 때문에 근접한 주성분간에 연관 관게가 최소가 되기 위해서는 서로 수직(orthogonal)한 것이 좋은 주성분이 된다 (PC1과 PC2). 

![image](https://github.com/DooHub/Machine-Learning/assets/99073912/b8fc80c7-9a00-4595-922d-0e1636a3615f)
[http://wolfpack.hnu.ac.kr/stat_notes/elem_stat/fall20/mva_pca.pdf]


```python

import numpy as np
from scipy import linalg,sparse
#선형 대수학 계산 하기

#행렬 생성
A=np.matrix(np.ranodm.random((2,2))) #임의의 2X2 행렬
b=np.random.random((2,2))  # 2X2 numpy arrary생성
B=np.asmatrix(b)  #2차원 배열을 행렬로 변환
C=np.mat(np.random.random((10,5))) # 임의의 10X5 행렬
D=np.mat([[3,4],[5,6]]) # 2차원 리스트를 행렬로 표현

A.I #A의 역행렬
lianlg.det(A) # A의 행렬식
A.T #A의 전치 행렬
lianlg.det(A) #A의 행렬식
A.T #A의 전치행렬

np.add(A,D)
np.substract(A,D)
np.divide(A,D)

D@B #행렬의 곱
np.dot(D,B)#행렬곱 numpy로 표시
np.multiply(D,B) #행렬곱이 아닌 각 element간 곱셈

linalg.eigvals(A)#행렬 A의 고윳값
la,v=linalg.eig(A) # la는 고윳값, v는 고유벡터
```
